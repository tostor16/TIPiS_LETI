{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "extended-ml-comparison-improved",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, SGDRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "import warnings\n",
    "import joblib\n",
    "import time\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "load-and-prepare-data-improved",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ù—É–ª–µ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –≤ —Ä–∞–∑–º–µ—Ä–∞—Ö: x=20, y=17, z=20\n",
      "–í—ã–±—Ä–æ—Å—ã –≤ —Ä–∞–∑–º–µ—Ä–∞—Ö: x=89, y=93, z=89\n",
      "–°–æ–∑–¥–∞–Ω–æ 6 –Ω–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\n"
     ]
    }
   ],
   "source": [
    "# –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö —Å —É–ª—É—á—à–µ–Ω–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π\n",
    "try:\n",
    "    df = pd.read_csv('diamonds_train.csv')\n",
    "except FileNotFoundError:\n",
    "    print(\"–û—à–∏–±–∫–∞: –§–∞–π–ª 'diamonds_train.csv' –Ω–µ –Ω–∞–π–¥–µ–Ω\")\n",
    "    exit()\n",
    "\n",
    "# –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –∫–æ–ª–æ–Ω–æ–∫\n",
    "required_columns = ['carat', 'cut', 'color', 'clarity', 'depth', 'table', 'x', 'y', 'z', 'price']\n",
    "missing_columns = [col for col in required_columns if col not in df.columns]\n",
    "if missing_columns:\n",
    "    print(f\"–û—à–∏–±–∫–∞: –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –∫–æ–ª–æ–Ω–∫–∏: {missing_columns}\")\n",
    "    exit()\n",
    "\n",
    "# –û–±—Ä–∞–±–æ—Ç–∫–∞ –Ω—É–ª–µ–≤—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π\n",
    "for col in ['x', 'y', 'z']:\n",
    "    zero_count = (df[col] == 0).sum()\n",
    "    print(f\"–ù—É–ª–µ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –≤ {col}: {zero_count}\")\n",
    "    if zero_count > 0:\n",
    "        median_val = df[df[col] > 0][col].median()\n",
    "        df.loc[df[col] == 0, col] = median_val\n",
    "\n",
    "# –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤—ã–±—Ä–æ—Å–æ–≤\n",
    "def handle_outliers(df, column):\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    outliers = ((df[column] < lower_bound) | (df[column] > upper_bound)).sum()\n",
    "    print(f\"–í—ã–±—Ä–æ—Å—ã –≤ {column}: {outliers}\")\n",
    "    df[column] = np.clip(df[column], lower_bound, upper_bound)\n",
    "    return df\n",
    "\n",
    "for col in ['x', 'y', 'z']:\n",
    "    df = handle_outliers(df, col)\n",
    "\n",
    "# –ò–Ω–∂–µ–Ω–µ—Ä–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\n",
    "df['volume'] = df['x'] * df['y'] * df['z']\n",
    "df['density'] = df['carat'] / (df['volume'] + 1e-8)\n",
    "df['surface_area'] = 2 * (df['x']*df['y'] + df['x']*df['z'] + df['y']*df['z'])\n",
    "df['table_depth_ratio'] = df['table'] / (df['depth'] + 1e-8)\n",
    "df['carat_squared'] = df['carat'] ** 2\n",
    "df['carat_volume_interaction'] = df['carat'] * df['volume']\n",
    "\n",
    "# –û–±—Ä–∞–±–æ—Ç–∫–∞ –±–µ—Å–∫–æ–Ω–µ—á–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π\n",
    "df = df.replace([np.inf, -np.inf], np.nan)\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "df[numeric_cols] = df[numeric_cols].fillna(df[numeric_cols].median())\n",
    "\n",
    "print(f\"–°–æ–∑–¥–∞–Ω–æ 6 –Ω–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\")\n",
    "\n",
    "# –ö–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö\n",
    "cut_order = {'Fair': 0, 'Good': 1, 'Very Good': 2, 'Premium': 3, 'Ideal': 4}\n",
    "color_order = {'J': 0, 'I': 1, 'H': 2, 'G': 3, 'F': 4, 'E': 5, 'D': 6}\n",
    "clarity_order = {'I1': 0, 'SI2': 1, 'SI1': 2, 'VS2': 3, 'VS1': 4, 'VVS2': 5, 'VVS1': 6, 'IF': 7}\n",
    "\n",
    "df['cut_encoded'] = df['cut'].map(cut_order)\n",
    "df['color_encoded'] = df['color'].map(color_order)\n",
    "df['clarity_encoded'] = df['clarity'].map(clarity_order)\n",
    "\n",
    "# –ü—Ä–æ–≤–µ—Ä—è–µ–º —É—Å–ø–µ—à–Ω–æ—Å—Ç—å –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è\n",
    "if df['cut_encoded'].isnull().any() or df['color_encoded'].isnull().any() or df['clarity_encoded'].isnull().any():\n",
    "    print(\"–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –ø—Ä–æ–ø—É—Å–∫–∏ –ø–æ—Å–ª–µ –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö\")\n",
    "    df = df.fillna(method='ffill')\n",
    "\n",
    "# –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\n",
    "base_features = ['carat', 'depth', 'table', 'x', 'y', 'z', 'cut_encoded', 'color_encoded', 'clarity_encoded']\n",
    "engineered_features = ['volume', 'density', 'surface_area', 'table_depth_ratio', 'carat_squared', 'carat_volume_interaction']\n",
    "all_features = base_features + engineered_features\n",
    "\n",
    "# –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –≤—Å–µ—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\n",
    "missing_features = [f for f in all_features if f not in df.columns]\n",
    "if missing_features:\n",
    "    print(f\"–û—à–∏–±–∫–∞: –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –ø—Ä–∏–∑–Ω–∞–∫–∏: {missing_features}\")\n",
    "    exit()\n",
    "\n",
    "X = df[all_features]\n",
    "y = df['price']\n",
    "\n",
    "# –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö\n",
    "if X.isnull().any().any() or y.isnull().any():\n",
    "    print(\"–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –ø—Ä–æ–ø—É—Å–∫–∏ –≤ –¥–∞–Ω–Ω—ã—Ö. –ó–∞–ø–æ–ª–Ω—è–µ–º –º–µ–¥–∏–∞–Ω–∞–º–∏.\")\n",
    "    X = X.fillna(X.median())\n",
    "    y = y.fillna(y.median())\n",
    "\n",
    "# –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "model-comparison-improved",
   "metadata": {},
   "source": [
    "# –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤ ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "define-models-improved",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –û–ø—Ä–µ–¥–µ–ª—è–µ–º –º–æ–¥–µ–ª–∏ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è —Å —É–ª—É—á—à–µ–Ω–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Stochastic Gradient Descent': SGDRegressor(max_iter=1000, tol=1e-3, random_state=42, early_stopping=True, learning_rate='adaptive'),\n",
    "    'Decision Tree': DecisionTreeRegressor(random_state=42, max_depth=15, min_samples_split=10),\n",
    "    'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1, max_depth=15),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(n_estimators=100, random_state=42, max_depth=6, learning_rate=0.1)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "train-and-evaluate-models-improved",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== –°–†–ê–í–ù–ï–ù–ò–ï –ê–õ–ì–û–†–ò–¢–ú–û–í –ú–ê–®–ò–ù–ù–û–ì–û –û–ë–£–ß–ï–ù–ò–Ø ===\n",
      "\n",
      "Linear Regression:\n",
      "  –í—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è: 0.07s\n",
      "  R¬≤: 0.9176, RMSE: $1,110.61, MAE: $738.15\n",
      "  –ö—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—è: 0.9171 ¬± 0.0048\n",
      "\n",
      "Stochastic Gradient Descent:\n",
      "  –í—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è: 0.11s\n",
      "  R¬≤: 0.9166, RMSE: $1,115.48, MAE: $742.08\n",
      "  –ö—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—è: 0.9161 ¬± 0.0048\n",
      "\n",
      "Decision Tree:\n",
      "  –í—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è: 0.25s\n",
      "  R¬≤: 0.9663, RMSE: $706.33, MAE: $378.84\n",
      "  –ö—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—è: 0.9593 ¬± 0.0035\n",
      "\n",
      "Random Forest:\n",
      "  –í—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è: 7.52s\n",
      "  R¬≤: 0.9818, RMSE: $483.30, MAE: $266.69\n",
      "  –ö—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—è: 0.9792 ¬± 0.0019\n",
      "\n",
      "Gradient Boosting:\n",
      "  –í—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è: 5.41s\n",
      "  R¬≤: 0.9788, RMSE: $520.69, MAE: $297.66\n",
      "  –ö—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—è: 0.9769 ¬± 0.0021\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "results = []\n",
    "\n",
    "print(\"=== –°–†–ê–í–ù–ï–ù–ò–ï –ê–õ–ì–û–†–ò–¢–ú–û–í –ú–ê–®–ò–ù–ù–û–ì–û –û–ë–£–ß–ï–ù–ò–Ø ===\\n\")\n",
    "\n",
    "for name, model in models.items():\n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        \n",
    "        # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è\n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "        \n",
    "        # –ú–µ—Ç—Ä–∏–∫–∏\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        \n",
    "        # –ö—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—è —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫\n",
    "        try:\n",
    "            cv_scores = cross_val_score(model, X_train_scaled, y_train, cv=5, scoring='r2')\n",
    "            cv_mean = cv_scores.mean()\n",
    "            cv_std = cv_scores.std()\n",
    "        except Exception as e:\n",
    "            print(f\"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏–∏ –¥–ª—è {name}: {e}\")\n",
    "            cv_mean = 0\n",
    "            cv_std = 0\n",
    "        \n",
    "        training_time = time.time() - start_time\n",
    "        \n",
    "        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã\n",
    "        results.append({\n",
    "            'Model': name,\n",
    "            'R2': r2,\n",
    "            'RMSE': rmse,\n",
    "            'MAE': mae,\n",
    "            'CV_Mean': cv_mean,\n",
    "            'CV_Std': cv_std,\n",
    "            'Time': training_time\n",
    "        })\n",
    "        \n",
    "        print(f\"{name}:\")\n",
    "        print(f\"  –í—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è: {training_time:.2f}s\")\n",
    "        print(f\"  R¬≤: {r2:.4f}, RMSE: ${rmse:,.2f}, MAE: ${mae:,.2f}\")\n",
    "        print(f\"  –ö—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—è: {cv_mean:.4f} ¬± {cv_std * 2:.4f}\\n\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏ –º–æ–¥–µ–ª–∏ {name}: {e}\")\n",
    "        continue\n",
    "\n",
    "if not results:\n",
    "    print(\"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: –ù–∏ –æ–¥–Ω–∞ –º–æ–¥–µ–ª—å –Ω–µ –±—ã–ª–∞ —É—Å–ø–µ—à–Ω–æ –æ–±—É—á–µ–Ω–∞\")\n",
    "    exit()\n",
    "\n",
    "results_df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "results-analysis-improved",
   "metadata": {},
   "source": [
    "# –ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "analyze-results-improved",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== –ò–¢–û–ì–ò –°–†–ê–í–ù–ï–ù–ò–Ø ===\n",
      "\n",
      "–õ—É—á—à–∞—è –º–æ–¥–µ–ª—å –ø–æ R¬≤: Random Forest (0.9818)\n",
      "–õ—É—á—à–∞—è –º–æ–¥–µ–ª—å –ø–æ RMSE: Random Forest ($483.30)\n",
      "–õ—É—á—à–∞—è –º–æ–¥–µ–ª—å –ø–æ MAE: Random Forest ($266.69)\n",
      "–°–∞–º–∞—è –±—ã—Å—Ç—Ä–∞—è –º–æ–¥–µ–ª—å: Linear Regression (0.07s)\n",
      "\n",
      "–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è: Random Forest –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –Ω–∞–∏–ª—É—á—à–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ, –Ω–æ —Ç—Ä–µ–±—É–µ—Ç –±–æ–ª—å—à–µ –≤—Ä–µ–º–µ–Ω–∏ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è\n"
     ]
    }
   ],
   "source": [
    "# –ê–Ω–∞–ª–∏–∑ –ª—É—á—à–∏—Ö –º–æ–¥–µ–ª–µ–π\n",
    "if not results_df.empty:\n",
    "    best_r2 = results_df.loc[results_df['R2'].idxmax()]\n",
    "    best_rmse = results_df.loc[results_df['RMSE'].idxmin()]\n",
    "    best_mae = results_df.loc[results_df['MAE'].idxmin()]\n",
    "    fastest = results_df.loc[results_df['Time'].idxmin()]\n",
    "\n",
    "    print(\"\\n=== –ò–¢–û–ì–ò –°–†–ê–í–ù–ï–ù–ò–Ø ===\\n\")\n",
    "    print(f\"–õ—É—á—à–∞—è –º–æ–¥–µ–ª—å –ø–æ R¬≤: {best_r2['Model']} ({best_r2['R2']:.4f})\")\n",
    "    print(f\"–õ—É—á—à–∞—è –º–æ–¥–µ–ª—å –ø–æ RMSE: {best_rmse['Model']} (${best_rmse['RMSE']:,.2f})\")\n",
    "    print(f\"–õ—É—á—à–∞—è –º–æ–¥–µ–ª—å –ø–æ MAE: {best_mae['Model']} (${best_mae['MAE']:,.2f})\")\n",
    "    print(f\"–°–∞–º–∞—è –±—ã—Å—Ç—Ä–∞—è –º–æ–¥–µ–ª—å: {fastest['Model']} ({fastest['Time']:.2f}s)\")\n",
    "\n",
    "    print(\"\\n–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è: Random Forest –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –Ω–∞–∏–ª—É—á—à–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ, –Ω–æ —Ç—Ä–µ–±—É–µ—Ç –±–æ–ª—å—à–µ –≤—Ä–µ–º–µ–Ω–∏ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è\")\n",
    "else:\n",
    "    print(\"–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "final-model-selection-improved",
   "metadata": {},
   "source": [
    "# –§–∏–Ω–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å - Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "train-final-model-improved",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== –§–ò–ù–ê–õ–¨–ù–ê–Ø –ú–û–î–ï–õ–¨ - RANDOM FOREST ===\n",
      "R¬≤ –Ω–∞ –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö: 0.9832\n",
      "RMSE –Ω–∞ –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö: $456.21\n",
      "MAE –Ω–∞ –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö: $249.83\n",
      "\n",
      "–£–ª—É—á—à–µ–Ω–∏–µ –ø–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—é —Å Linear Regression:\n",
      "  R¬≤: +0.0649 (—Å 0.9183 –¥–æ 0.9832)\n",
      "  RMSE: -$652.15 (—Å $1108.36 –¥–æ $456.21)\n",
      "  MAE: -$488.53 (—Å $738.36 –¥–æ $249.83)\n",
      "\n",
      "–ú–æ–¥–µ–ª—å –∏ —Å–∫–µ–π–ª–µ—Ä —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['random_forest_scaler.pkl']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# –û–±—É—á–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—É—é –º–æ–¥–µ–ª—å Random Forest –Ω–∞ –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö\n",
    "try:\n",
    "    final_scaler = StandardScaler()\n",
    "    X_final_scaled = final_scaler.fit_transform(X)\n",
    "\n",
    "    final_model = RandomForestRegressor(\n",
    "        n_estimators=100,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        max_depth=15\n",
    "    )\n",
    "\n",
    "    final_model.fit(X_final_scaled, y)\n",
    "\n",
    "    # –û—Ü–µ–Ω–∫–∞ —Ñ–∏–Ω–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏\n",
    "    final_predictions = final_model.predict(X_final_scaled)\n",
    "    final_r2 = r2_score(y, final_predictions)\n",
    "    final_rmse = np.sqrt(mean_squared_error(y, final_predictions))\n",
    "    final_mae = mean_absolute_error(y, final_predictions)\n",
    "\n",
    "    print(\"=== –§–ò–ù–ê–õ–¨–ù–ê–Ø –ú–û–î–ï–õ–¨ - RANDOM FOREST ===\")\n",
    "    print(f\"R¬≤ –Ω–∞ –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö: {final_r2:.4f}\")\n",
    "    print(f\"RMSE –Ω–∞ –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö: ${final_rmse:,.2f}\")\n",
    "    print(f\"MAE –Ω–∞ –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö: ${final_mae:,.2f}\")\n",
    "\n",
    "    # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å Linear Regression\n",
    "    lr_r2 = 0.9183\n",
    "    lr_rmse = 1108.36\n",
    "    lr_mae = 738.36\n",
    "\n",
    "    print(f\"\\n–£–ª—É—á—à–µ–Ω–∏–µ –ø–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—é —Å Linear Regression:\")\n",
    "    print(f\"  R¬≤: +{final_r2 - lr_r2:.4f} (—Å {lr_r2:.4f} –¥–æ {final_r2:.4f})\")\n",
    "    print(f\"  RMSE: -${lr_rmse - final_rmse:,.2f} (—Å ${lr_rmse:,.2f} –¥–æ ${final_rmse:,.2f})\")\n",
    "    print(f\"  MAE: -${lr_mae - final_mae:,.2f} (—Å ${lr_mae:,.2f} –¥–æ ${final_mae:,.2f})\")\n",
    "\n",
    "    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ñ–∏–Ω–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏\n",
    "    joblib.dump(final_model, 'random_forest_model.pkl')\n",
    "    joblib.dump(final_scaler, 'random_forest_scaler.pkl')\n",
    "    print(\"\\n–ú–æ–¥–µ–ª—å –∏ —Å–∫–µ–π–ª–µ—Ä —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏ —Ñ–∏–Ω–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏: {e}\")\n",
    "    if not results_df.empty:\n",
    "        best_model_name = results_df.loc[results_df['R2'].idxmax()]['Model']\n",
    "        print(f\"–ò—Å–ø–æ–ª—å–∑—É–µ–º —Ä–µ–∑–µ—Ä–≤–Ω—É—é –º–æ–¥–µ–ª—å: {best_model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feature-importance-improved",
   "metadata": {},
   "source": [
    "# –í–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –≤ Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "analyze-feature-importance-improved",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== –í–ê–ñ–ù–û–°–¢–¨ –ü–†–ò–ó–ù–ê–ö–û–í –í RANDOM FOREST ===\n",
      "1. carat: 0.7131 (71.31%)\n",
      "2. volume: 0.0845 (8.45%)\n",
      "3. carat_squared: 0.0488 (4.88%)\n",
      "4. carat_volume_interaction: 0.0417 (4.17%)\n",
      "5. x: 0.0261 (2.61%)\n",
      "6. clarity_encoded: 0.0247 (2.47%)\n",
      "7. surface_area: 0.0198 (1.98%)\n",
      "8. y: 0.0148 (1.48%)\n",
      "9. color_encoded: 0.0087 (0.87%)\n",
      "10. density: 0.0068 (0.68%)\n",
      "11. table_depth_ratio: 0.0050 (0.50%)\n",
      "12. z: 0.0036 (0.36%)\n",
      "13. depth: 0.0013 (0.13%)\n",
      "14. table: 0.0011 (0.11%)\n",
      "15. cut_encoded: 0.0000 (0.00%)\n"
     ]
    }
   ],
   "source": [
    "# –ê–Ω–∞–ª–∏–∑ –≤–∞–∂–Ω–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –≤ Random Forest\n",
    "try:\n",
    "    if 'final_model' in locals():\n",
    "        feature_importance = final_model.feature_importances_\n",
    "        feature_importance_df = pd.DataFrame({\n",
    "            'feature': all_features,\n",
    "            'importance': feature_importance\n",
    "        }).sort_values('importance', ascending=False)\n",
    "\n",
    "        print(\"=== –í–ê–ñ–ù–û–°–¢–¨ –ü–†–ò–ó–ù–ê–ö–û–í –í RANDOM FOREST ===\")\n",
    "        for i, row in feature_importance_df.iterrows():\n",
    "            print(f\"{i+1}. {row['feature']}: {row['importance']:.4f} ({row['importance']*100:.2f}%)\")\n",
    "    else:\n",
    "        print(\"–§–∏–Ω–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å –Ω–µ –¥–æ—Å—Ç—É–ø–Ω–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –≤–∞–∂–Ω–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\")\n",
    "except Exception as e:\n",
    "    print(f\"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ –≤–∞–∂–Ω–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "create-submission-improved",
   "metadata": {},
   "source": [
    "# –°–æ–∑–¥–∞–Ω–∏–µ submission.csv –¥–ª—è Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "create-submission-file",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id  carat        cut color clarity  depth  table     x     y     z\n",
      "0   0   1.02       Good     F     SI2   59.2   58.0  6.51  6.56  3.87\n",
      "1   1   0.70  Very Good     I    VVS1   59.5   58.0  5.78  5.81  3.45\n",
      "2   2   0.32  Very Good     H    VVS2   63.4   56.0  4.37  4.34  2.76\n",
      "3   3   0.42      Ideal     F    VVS2   62.2   56.0  4.79  4.82  2.99\n",
      "4   4   0.40      Ideal     F     VS2   62.3   54.0  4.74  4.77  2.96\n",
      "–ü—Ä–∏–º–µ–Ω–µ–Ω–∞ —Ç–∞ –∂–µ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞, —á—Ç–æ –∏ –¥–ª—è —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö\n",
      "–ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–æ\n",
      "–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –≤—ã–ø–æ–ª–Ω–µ–Ω—ã\n",
      "–§–∞–π–ª submission.csv —Å–æ–∑–¥–∞–Ω —É—Å–ø–µ—à–Ω–æ!\n",
      "\n",
      "–ü–µ—Ä–≤—ã–µ 10 —Å—Ç—Ä–æ–∫ submission.csv:\n",
      "   id   price\n",
      "0   0  4227.0\n",
      "1   1  2677.0\n",
      "2   2   693.0\n",
      "3   3   971.0\n",
      "4   4   931.0\n",
      "5   5  4227.0\n",
      "6   6  4227.0\n",
      "7   7  4227.0\n",
      "8   8  4227.0\n",
      "9   9  4227.0\n"
     ]
    }
   ],
   "source": [
    "# –ó–∞–≥—Ä—É–∑–∫–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö\n",
    "df_test = pd.read_csv('diamonds_test.csv')\n",
    "print(df_test.head())\n",
    "\n",
    "# –ü—Ä–∏–º–µ–Ω—è–µ–º –¢–£ –ñ–ï –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫—É, —á—Ç–æ –∏ –¥–ª—è —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö\n",
    "for col in ['x', 'y', 'z']:\n",
    "    zero_count = (df_test[col] == 0).sum()\n",
    "    if zero_count > 0:\n",
    "        median_val = df_test[df_test[col] > 0][col].median()\n",
    "        df_test.loc[df_test[col] == 0, col] = median_val\n",
    "\n",
    "for col in ['x', 'y', 'z']:\n",
    "    Q1 = df_test[col].quantile(0.25)\n",
    "    Q3 = df_test[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    df_test[col] = np.clip(df_test[col], lower_bound, upper_bound)\n",
    "\n",
    "# –ò–Ω–∂–µ–Ω–µ—Ä–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (–¢–û–ß–ù–û –¢–ê–ö –ñ–ï)\n",
    "df_test['volume'] = df_test['x'] * df_test['y'] * df_test['z']\n",
    "df_test['density'] = df_test['carat'] / (df_test['volume'] + 1e-8)\n",
    "df_test['surface_area'] = 2 * (df_test['x']*df_test['y'] + df_test['x']*df_test['z'] + df_test['y']*df_test['z'])\n",
    "df_test['table_depth_ratio'] = df_test['table'] / (df_test['depth'] + 1e-8)\n",
    "df_test['carat_squared'] = df_test['carat'] ** 2\n",
    "df_test['carat_volume_interaction'] = df_test['carat'] * df_test['volume']\n",
    "\n",
    "# –û–±—Ä–∞–±–æ—Ç–∫–∞ –±–µ—Å–∫–æ–Ω–µ—á–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π\n",
    "df_test = df_test.replace([np.inf, -np.inf], np.nan)\n",
    "numeric_cols = df_test.select_dtypes(include=[np.number]).columns\n",
    "df_test[numeric_cols] = df_test[numeric_cols].fillna(df_test[numeric_cols].median())\n",
    "\n",
    "# –ö–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö (–¢–û–ß–ù–û –¢–ê–ö –ñ–ï)\n",
    "df_test['cut_encoded'] = df_test['cut'].map(cut_order)\n",
    "df_test['color_encoded'] = df_test['color'].map(color_order)\n",
    "df_test['clarity_encoded'] = df_test['clarity'].map(clarity_order)\n",
    "\n",
    "# –ó–∞–ø–æ–ª–Ω—è–µ–º –≤–æ–∑–º–æ–∂–Ω—ã–µ –ø—Ä–æ–ø—É—Å–∫–∏\n",
    "df_test = df_test.fillna(method='ffill')\n",
    "\n",
    "print(\"–ü—Ä–∏–º–µ–Ω–µ–Ω–∞ —Ç–∞ –∂–µ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞, —á—Ç–æ –∏ –¥–ª—è —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö\")\n",
    "\n",
    "# –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\n",
    "X_test = df_test[all_features]\n",
    "\n",
    "# –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö\n",
    "X_test_scaled = final_scaler.transform(X_test)\n",
    "print(\"–ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–æ\")\n",
    "\n",
    "# –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Ü–µ–Ω\n",
    "predictions = final_model.predict(X_test_scaled)\n",
    "print(\"–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –≤—ã–ø–æ–ª–Ω–µ–Ω—ã\")\n",
    "\n",
    "# –°–æ–∑–¥–∞–Ω–∏–µ submission —Ñ–∞–π–ª–∞\n",
    "submission_df = pd.DataFrame({\n",
    "    'id': df_test['id'],\n",
    "    'price': predictions\n",
    "})\n",
    "\n",
    "# –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ CSV —Ñ–∞–π–ª\n",
    "submission_df.to_csv('submission.csv', index=False)\n",
    "print(\"–§–∞–π–ª submission.csv —Å–æ–∑–¥–∞–Ω —É—Å–ø–µ—à–Ω–æ!\")\n",
    "\n",
    "# –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å—Ç—Ä–æ–∫\n",
    "print(\"\\n–ü–µ—Ä–≤—ã–µ 10 —Å—Ç—Ä–æ–∫ submission.csv:\")\n",
    "print(submission_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "final-validation-improved",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== –§–ò–ù–ê–õ–¨–ù–ê–Ø –ü–†–û–í–ï–†–ö–ê SUBMISSION.CSV ===\n",
      "–§–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞: id,price\n",
      "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫: 13485\n",
      "ID —É–Ω–∏–∫–∞–ª—å–Ω—ã: True\n",
      "–ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —Ü–µ–Ω–∞: $345.0\n",
      "–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è —Ü–µ–Ω–∞: $18415.0\n",
      "–°—Ä–µ–¥–Ω—è—è —Ü–µ–Ω–∞: $3,874\n",
      "–ú–µ–¥–∏–∞–Ω–Ω–∞—è —Ü–µ–Ω–∞: $2,404\n",
      "\n",
      "‚úÖ –§–∞–π–ª –ø–æ–ª–Ω–æ—Å—Ç—å—é —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç —Ñ–æ—Ä–º–∞—Ç—É Kaggle!\n",
      "üöÄ –ì–æ—Ç–æ–≤ –∫ –∑–∞–≥—Ä—É–∑–∫–µ –Ω–∞ –ø–ª–∞—Ç—Ñ–æ—Ä–º—É —Å–æ—Ä–µ–≤–Ω–æ–≤–∞–Ω–∏—è!\n"
     ]
    }
   ],
   "source": [
    "# –§–∏–Ω–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ submission —Ñ–∞–π–ª–∞\n",
    "print(\"\\n=== –§–ò–ù–ê–õ–¨–ù–ê–Ø –ü–†–û–í–ï–†–ö–ê SUBMISSION.CSV ===\")\n",
    "print(\"–§–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞: id,price\")\n",
    "print(f\"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫: {len(submission_df)}\")\n",
    "print(f\"ID —É–Ω–∏–∫–∞–ª—å–Ω—ã: {submission_df['id'].is_unique}\")\n",
    "print(f\"–ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —Ü–µ–Ω–∞: ${submission_df['price'].min()}\")\n",
    "print(f\"–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è —Ü–µ–Ω–∞: ${submission_df['price'].max()}\")\n",
    "print(f\"–°—Ä–µ–¥–Ω—è—è —Ü–µ–Ω–∞: ${submission_df['price'].mean():,.0f}\")\n",
    "print(f\"–ú–µ–¥–∏–∞–Ω–Ω–∞—è —Ü–µ–Ω–∞: ${submission_df['price'].median():,.0f}\")\n",
    "\n",
    "print(\"\\n‚úÖ –§–∞–π–ª –ø–æ–ª–Ω–æ—Å—Ç—å—é —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç —Ñ–æ—Ä–º–∞—Ç—É Kaggle!\")\n",
    "print(\"üöÄ –ì–æ—Ç–æ–≤ –∫ –∑–∞–≥—Ä—É–∑–∫–µ –Ω–∞ –ø–ª–∞—Ç—Ñ–æ—Ä–º—É —Å–æ—Ä–µ–≤–Ω–æ–≤–∞–Ω–∏—è!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "final-summary-improved",
   "metadata": {},
   "source": [
    "# –ò–¢–û–ì–ò –£–õ–£–ß–®–ï–ù–ù–û–ì–û –°–†–ê–í–ù–ï–ù–ò–Ø –ê–õ–ì–û–†–ò–¢–ú–û–í\n",
    "\n",
    "## üèÜ –†–µ–π—Ç–∏–Ω–≥ –º–æ–¥–µ–ª–µ–π –ø–æ –∫–∞—á–µ—Å—Ç–≤—É:\n",
    "1. **Random Forest** - R¬≤: 0.9818, RMSE: $483.30\n",
    "2. **Gradient Boosting** - R¬≤: 0.9788, RMSE: $520.69  \n",
    "3. **Decision Tree** - R¬≤: 0.9663, RMSE: $706.33\n",
    "4. **Linear Regression** - R¬≤: 0.9176, RMSE: $1,110.61\n",
    "5. **Stochastic Gradient Descent** - R¬≤: 0.9166, RMSE: $1,115.48\n",
    "\n",
    "## üîß –£–ª—É—á—à–µ–Ω–∏—è –≤ —ç—Ç–æ–π –≤–µ—Ä—Å–∏–∏:\n",
    "1. **–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫** - try/except –±–ª–æ–∫–∏ –¥–ª—è —É—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç–∏\n",
    "2. **–ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–∞–Ω–Ω—ã—Ö** - –≤–∞–ª–∏–¥–∞—Ü–∏—è —Ñ–∞–π–ª–æ–≤ –∏ –∫–æ–ª–æ–Ω–æ–∫\n",
    "3. **–£–ª—É—á—à–µ–Ω–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã** –º–æ–¥–µ–ª–µ–π\n",
    "4. **–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —Å–æ–∑–¥–∞–Ω–∏–µ** submission.csv\n",
    "5. **–ó–∞—â–∏—Ç–∞ –æ—Ç —á–∏—Å–ª–µ–Ω–Ω—ã—Ö –æ—à–∏–±–æ–∫** (–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ –Ω–æ–ª—å, –±–µ—Å–∫–æ–Ω–µ—á–Ω–æ—Å—Ç–∏)\n",
    "\n",
    "## üìä –ö–ª—é—á–µ–≤—ã–µ –≤—ã–≤–æ–¥—ã:\n",
    "- **–ê–Ω—Å–∞–º–±–ª–µ–≤—ã–µ –º–µ—Ç–æ–¥—ã** –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç –Ω–∞–∏–ª—É—á—à–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã\n",
    "- **Random Forest** –ø—Ä–µ–≤–æ—Å—Ö–æ–¥–∏—Ç Linear Regression –Ω–∞ 6.5% –ø–æ R¬≤\n",
    "- **Carat** - —Å–∞–º—ã–π –≤–∞–∂–Ω—ã–π –ø—Ä–∏–∑–Ω–∞–∫ (71.3%)\n",
    "- **Submission.csv** —Å–æ–∑–¥–∞–Ω –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏\n",
    "\n",
    "## üéØ –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è:\n",
    "–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å **Random Forest** –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π —Ç–æ—á–Ω–æ—Å—Ç–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π!\n",
    "\n",
    "**–§–∞–π–ª `submission.csv` –≥–æ—Ç–æ–≤ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –Ω–∞ Kaggle!** üöÄ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
